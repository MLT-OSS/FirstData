#!/usr/bin/env python3
"""
DataSource Hub MCP è‡ªåŠ¨åŒ–æµ‹è¯•è„šæœ¬

è¿è¡Œtest_cases.mdä¸­å®šä¹‰çš„æ‰€æœ‰æµ‹è¯•ç”¨ä¾‹ï¼Œå¹¶ç”Ÿæˆè¯¦ç»†çš„æµ‹è¯•æŠ¥å‘Šã€‚
"""

import json
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple
import uuid
import requests

# æµ‹è¯•ç”¨ä¾‹å®šä¹‰
TEST_CASES = [
    {
        "id": 1,
        "name": "ä¸­å›½å®è§‚ç»æµä¸è´§å¸æ”¿ç­–å…³è”åˆ†æ",
        "query": "æˆ‘æƒ³åˆ†æä¸­å›½è¿‘10å¹´çš„ç»æµå¢é•¿ä¸è´§å¸æ”¿ç­–ä¹‹é—´çš„å…³ç³»ã€‚å…·ä½“æ¥è¯´,æˆ‘éœ€è¦ç ”ç©¶GDPå¢é•¿ç‡ã€è´§å¸ä¾›åº”é‡(M1/M2)ã€åˆ©ç‡å˜åŒ–ä»¥åŠå›ºå®šèµ„äº§æŠ•èµ„ä¹‹é—´çš„å…³è”æ€§,å¹¶è¯„ä¼°å®½æ¾è´§å¸æ”¿ç­–å¯¹å®ä½“ç»æµçš„ä¼ å¯¼æ•ˆæœå¦‚ä½•ã€‚è¯·å¸®æˆ‘æ‰¾åˆ°åˆé€‚çš„æ•°æ®æºã€‚",
        "expected_sources": ["National Bureau of Statistics of China", "People's Bank of China"],
        "category": "è¯¦ç»†æµ‹è¯•"
    },
    {
        "id": 2,
        "name": "å…¨çƒèƒ½æºè½¬å‹ä¸ç¢³ä¸­å’Œè·¯å¾„åˆ†æ",
        "query": "æˆ‘æ­£åœ¨ç ”ç©¶å…¨çƒä¸»è¦ç»æµä½“çš„èƒ½æºè½¬å‹è·¯å¾„ã€‚éœ€è¦åˆ†æä»¥ä¸‹é—®é¢˜:\n1. å…¨çƒå¯å†ç”Ÿèƒ½æº(å¤ªé˜³èƒ½ã€é£èƒ½ã€æ°´ç”µ)å æ¯”çš„å†å²è¶‹åŠ¿å’Œæœªæ¥é¢„æµ‹\n2. ä¸»è¦å›½å®¶(ä¸­å›½ã€ç¾å›½ã€æ¬§ç›Ÿ)çš„èƒ½æºæ¶ˆè´¹ç»“æ„å˜åŒ–\n3. ç¢³æ’æ”¾æ•°æ®å’Œå„å›½ç¢³ä¸­å’Œæ‰¿è¯ºçš„è¿›å±•\n4. èƒ½æºä»·æ ¼(çŸ³æ²¹ã€å¤©ç„¶æ°”ã€ç”µåŠ›)å¯¹èƒ½æºè½¬å‹çš„å½±å“\n\nè¯·æ¨èæƒå¨çš„èƒ½æºæ•°æ®æ¥æºã€‚",
        "expected_sources": ["IEA Energy Data", "World Bank Open Data", "BP Statistical Review"],
        "category": "è¯¦ç»†æµ‹è¯•"
    },
    {
        "id": 3,
        "name": "è‚¡ç¥¨å¸‚åœºæŠ€æœ¯åˆ†æä¸é‡åŒ–æŠ•èµ„ç­–ç•¥",
        "query": "æˆ‘æƒ³å¼€å‘ä¸€ä¸ªè‚¡ç¥¨é‡åŒ–äº¤æ˜“ç­–ç•¥,éœ€è¦ä»¥ä¸‹æ•°æ®:\n1. ç¾è‚¡å’ŒAè‚¡ä¸»è¦è‚¡ç¥¨çš„å†å²ä»·æ ¼æ•°æ®(æœ€å¥½æœ‰20å¹´ä»¥ä¸Šå†å²)\n2. æŠ€æœ¯æŒ‡æ ‡æ•°æ®:ç§»åŠ¨å¹³å‡çº¿(SMA/EMA)ã€ç›¸å¯¹å¼ºå¼±æŒ‡æ ‡(RSI)ã€MACDã€å¸ƒæ—å¸¦ç­‰\n3. å®æ—¶æˆ–å‡†å®æ—¶çš„è‚¡ä»·æ•°æ®ç”¨äºå›æµ‹\n4. æœ€å¥½æœ‰APIæ¥å£,æ–¹ä¾¿ç¨‹åºåŒ–è®¿é—®\n5. äº¤æ˜“é‡æ•°æ®å’Œå¸‚åœºæƒ…ç»ªæŒ‡æ ‡\n\nè¯·æ¨èé€‚åˆé‡åŒ–äº¤æ˜“çš„æ•°æ®æºã€‚",
        "expected_sources": ["Alpha Vantage API"],
        "category": "è¯¦ç»†æµ‹è¯•"
    },
    {
        "id": 4,
        "name": "ä¸­å›½å¤–å•†æŠ•èµ„è¶‹åŠ¿ä¸äº§ä¸šæ”¿ç­–åˆ†æ",
        "query": "æˆ‘åœ¨åšä¸€ä¸ªå…³äºä¸­å›½å¤–å•†æŠ•èµ„ç¯å¢ƒçš„ç ”ç©¶æŠ¥å‘Š,éœ€è¦ä»¥ä¸‹æ•°æ®:\n1. è¿‘15å¹´ä¸­å›½FDI(å¤–å•†ç›´æ¥æŠ•èµ„)æµå…¥çš„è¡Œä¸šåˆ†å¸ƒå’Œå›½åˆ«æ¥æº\n2. ä¸­å›½ODI(å¯¹å¤–ç›´æ¥æŠ•èµ„)çš„ç›®çš„åœ°å›½å®¶å’ŒæŠ•èµ„é¢†åŸŸ\n3. å¤–å•†æŠ•èµ„ä¼ä¸šæ•°é‡å˜åŒ–è¶‹åŠ¿\n4. ä¸­å›½ç”µå­å•†åŠ¡å’Œé›¶å”®å¸‚åœºçš„å‘å±•æ•°æ®\n5. æœåŠ¡è´¸æ˜“æ•°æ®,ç‰¹åˆ«æ˜¯é‡‘èæœåŠ¡ã€ä¿¡æ¯æŠ€æœ¯æœåŠ¡ç­‰é«˜é™„åŠ å€¼æœåŠ¡\n6. åŒè¾¹ç»è´¸åå®šå’Œè‡ªè´¸åŒºæ”¿ç­–ä¿¡æ¯\n\nè¯·å¸®æˆ‘æ‰¾åˆ°å®˜æ–¹æ•°æ®æºã€‚",
        "expected_sources": ["Ministry of Commerce of China", "National Bureau of Statistics of China"],
        "category": "è¯¦ç»†æµ‹è¯•"
    },
    {
        "id": 5,
        "name": "æ–°å† ç–«æƒ…å¯¹å…¨çƒå«ç”Ÿç³»ç»Ÿçš„å½±å“ç ”ç©¶",
        "query": "æˆ‘åœ¨åšä¸€ä¸ªå…³äºæ–°å† ç–«æƒ…å¯¹å…¨çƒå…¬å…±å«ç”Ÿç³»ç»Ÿå½±å“çš„æ–‡çŒ®ç»¼è¿°,éœ€è¦:\n1. æŸ¥æ‰¾2020-2024å¹´é—´å…³äºCOVID-19çš„å­¦æœ¯æ–‡çŒ®ã€ä¸´åºŠè¯•éªŒç ”ç©¶\n2. ç–«è‹—ç ”å‘ç›¸å…³çš„ç”Ÿç‰©åŒ»å­¦æ–‡çŒ®\n3. å…¬å…±å«ç”Ÿæ”¿ç­–å¹²é¢„æªæ–½çš„æ•ˆæœè¯„ä¼°ç ”ç©¶\n4. ç–«æƒ…å¯¹åŒ»ç–—èµ„æºåˆ†é…å’ŒåŒ»ç–—ç³»ç»ŸéŸ§æ€§çš„å½±å“ç ”ç©¶\n5. éœ€è¦èƒ½å¤ŸæŒ‰ç…§ä¸»é¢˜è¯(MeSH)ã€ä½œè€…ã€æœŸåˆŠã€èµ„åŠ©æœºæ„ç­‰ç»´åº¦æ£€ç´¢æ–‡çŒ®\n\nå“ªé‡Œå¯ä»¥æ‰¾åˆ°è¿™äº›ç”Ÿç‰©åŒ»å­¦æ–‡çŒ®?",
        "expected_sources": ["PubMed"],
        "category": "è¯¦ç»†æµ‹è¯•"
    },
    {
        "id": 6,
        "name": "ä¸­å›½æˆ¿åœ°äº§å¸‚åœºä¸åœ°æ–¹è´¢æ”¿å…³ç³»ç ”ç©¶",
        "query": "åœ¨å½“å‰ä¸­å›½æˆ¿åœ°äº§å¸‚åœºè°ƒæ•´çš„èƒŒæ™¯ä¸‹,æˆ‘æƒ³ç ”ç©¶æˆ¿åœ°äº§ä½è¿·å¯¹åœ°æ–¹æ”¿åºœè´¢æ”¿æ”¶å…¥çš„å½±å“ç¨‹åº¦ã€‚å…·ä½“éœ€è¦:\n1. åœ°æ–¹æ”¿åºœåœŸåœ°å‡ºè®©æ”¶å…¥(åœŸåœ°è´¢æ”¿)çš„å†å²æ•°æ®\n2. æˆ¿åœ°äº§ç›¸å…³ç¨æ”¶(å¥‘ç¨ã€åœŸåœ°å¢å€¼ç¨ç­‰)å åœ°æ–¹è´¢æ”¿æ”¶å…¥çš„æ¯”é‡\n3. æˆ¿åœ°äº§å¼€å‘æŠ•èµ„ã€å•†å“æˆ¿é”€å”®é¢ç§¯å’Œé‡‘é¢ç­‰å¸‚åœºæ•°æ®\n4. åœ°æ–¹æ”¿åºœå€ºåŠ¡è§„æ¨¡å’Œå¿å€ºå‹åŠ›æŒ‡æ ‡\n5. æœ€å¥½æœ‰çœçº§æˆ–åŸå¸‚çº§çš„ç»†åˆ†æ•°æ®,ç”¨äºåŒºåŸŸæ¯”è¾ƒåˆ†æ\n\nå“ªäº›å®˜æ–¹æ•°æ®æºå¯ä»¥æä¾›è¿™äº›ä¿¡æ¯?",
        "expected_sources": ["National Bureau of Statistics of China", "Ministry of Finance of China"],
        "category": "è¯¦ç»†æµ‹è¯•"
    },
    {
        "id": 7,
        "name": "å…¨çƒè´«å›°ä¸å‘å±•æ´åŠ©æ•ˆæœè¯„ä¼°",
        "query": "æˆ‘åœ¨ç ”ç©¶å›½é™…å‘å±•æ´åŠ©å¯¹å‡è´«çš„å®é™…æ•ˆæœã€‚éœ€è¦è·å–:\n1. å…¨çƒå’Œå„å›½çš„è´«å›°ç‡æ•°æ®(ç‰¹åˆ«æ˜¯æ’’å“ˆæ‹‰ä»¥å—éæ´²åœ°åŒº)\n2. å›½é™…å‘å±•æ´åŠ©èµ„é‡‘æµå‘æ•°æ®(æŒ‰å›½å®¶ã€éƒ¨é—¨ã€æ´åŠ©ç±»å‹åˆ†ç±»)\n3. å—æ´å›½çš„ç»æµå¢é•¿ã€äººç±»å‘å±•æŒ‡æ•°(HDI)ã€æ•™è‚²å’Œå¥åº·æŒ‡æ ‡\n4. å¤–å›½ç›´æ¥æŠ•èµ„(FDI)æ•°æ®,ç”¨äºå¯¹æ¯”æ´åŠ©ä¸æŠ•èµ„çš„æ•ˆæœ\n5. æ”¶å…¥åˆ†é…ä¸å¹³ç­‰æ•°æ®(åŸºå°¼ç³»æ•°ç­‰)\n6. æ•°æ®è¦èƒ½å¤Ÿè¿›è¡Œè·¨å›½æ¯”è¾ƒ,å¹¶ä¸”æ—¶é—´è·¨åº¦è‡³å°‘20å¹´\n\nè¯·æ¨èå›½é™…å‘å±•é¢†åŸŸçš„æƒå¨æ•°æ®æºã€‚",
        "expected_sources": ["World Bank Open Data", "African Development Bank"],
        "category": "è¯¦ç»†æµ‹è¯•"
    },
    {
        "id": 8,
        "name": "æ°”å€™å˜åŒ–å¯¹å†œä¸šç”Ÿäº§çš„å½±å“åˆ†æ",
        "query": "æˆ‘æƒ³ç ”ç©¶æ°”å€™å˜åŒ–å¯¹å…¨çƒç²®é£Ÿå®‰å…¨çš„å½±å“,éœ€è¦ä»¥ä¸‹æ•°æ®:\n1. å…¨çƒä¸»è¦ç²®é£Ÿä½œç‰©(å°éº¦ã€æ°´ç¨»ã€ç‰ç±³)çš„äº§é‡ã€ç§æ¤é¢ç§¯ã€å•äº§æ•°æ®\n2. æ°”å€™æ•°æ®:æ¸©åº¦ã€é™æ°´ã€æç«¯å¤©æ°”äº‹ä»¶é¢‘ç‡\n3. å„å›½å†œä¸šæ”¿ç­–å’Œç²®é£Ÿå‚¨å¤‡ä¿¡æ¯\n4. ç²®é£Ÿä»·æ ¼æŒ‡æ•°å’Œå›½é™…ç²®é£Ÿè´¸æ˜“æ•°æ®\n5. å†œä¸šæŠ€æœ¯ç ”å‘æŠ•å…¥å’Œæ¨å¹¿æ•°æ®\n6. åœŸåœ°åˆ©ç”¨å˜åŒ–å’ŒåœŸå£¤è´¨é‡æ•°æ®\n\nè¯·æ¨èå†œä¸šå’Œæ°”å€™é¢†åŸŸçš„æ•°æ®æºã€‚",
        "expected_sources": ["FAOSTAT", "NOAA Climate Data", "World Bank Open Data"],
        "category": "è¯¦ç»†æµ‹è¯•"
    },
    {
        "id": 9,
        "name": "é‡‘ä»·èµ°åŠ¿æŠ•èµ„åˆ†æ",
        "query": "è°ƒç ”åˆ†æä¸€ä¸‹é‡‘ä»·çš„èµ°åŠ¿å¹¶ç»™å‡ºæŠ•èµ„å»ºè®®",
        "expected_sources": ["Alpha Vantage API", "World Bank Open Data"],
        "category": "ç®€çŸ­æµ‹è¯•"
    },
    {
        "id": 10,
        "name": "ä¸­ç¾è´¸æ˜“å…³ç³»åˆ†æ",
        "query": "å¸®æˆ‘åˆ†æä¸€ä¸‹ä¸­ç¾è´¸æ˜“æˆ˜å¯¹ä¸¤å›½è¿›å‡ºå£çš„å½±å“,ç‰¹åˆ«æ˜¯é«˜ç§‘æŠ€äº§å“é¢†åŸŸ",
        "expected_sources": ["China Customs", "Ministry of Commerce of China", "U.S. Census Bureau"],
        "category": "ç®€çŸ­æµ‹è¯•"
    },
    {
        "id": 11,
        "name": "å…¨çƒèƒ½æºè½¬å‹è¶‹åŠ¿",
        "query": "æƒ³äº†è§£ä¸€ä¸‹å…¨çƒå¯å†ç”Ÿèƒ½æºçš„å‘å±•è¶‹åŠ¿,å“ªäº›å›½å®¶åšå¾—æ¯”è¾ƒå¥½",
        "expected_sources": ["IEA Energy Data", "World Bank Open Data"],
        "category": "ç®€çŸ­æµ‹è¯•"
    },
    {
        "id": 12,
        "name": "mRNAç–«è‹—æ–‡çŒ®ç»¼è¿°",
        "query": "æˆ‘éœ€è¦æŸ¥æ‰¾å…³äºmRNAç–«è‹—æŠ€æœ¯çš„æœ€æ–°ç ”ç©¶æ–‡çŒ®,åšä¸€ä¸ªæ–‡çŒ®ç»¼è¿°",
        "expected_sources": ["PubMed"],
        "category": "ç®€çŸ­æµ‹è¯•"
    },
    {
        "id": 13,
        "name": "ä¸­å›½æ¶ˆè´¹å¸‚åœºè¶‹åŠ¿",
        "query": "åˆ†æä¸€ä¸‹ä¸­å›½ç”µå•†å’Œçº¿ä¸‹é›¶å”®çš„å‘å±•è¶‹åŠ¿,ç–«æƒ…åæ¶ˆè´¹ä¹ æƒ¯æœ‰ä»€ä¹ˆå˜åŒ–",
        "expected_sources": ["National Bureau of Statistics of China", "Ministry of Commerce of China"],
        "category": "ç®€çŸ­æµ‹è¯•"
    },
    {
        "id": 14,
        "name": "æ°”å€™å˜åŒ–å¯¹å†œä¸šå½±å“",
        "query": "ç ”ç©¶æ°”å€™å˜åŒ–ä¼šä¸ä¼šå½±å“å…¨çƒç²®é£Ÿäº§é‡,éœ€è¦å„å›½çš„å†œä¸šå’Œæ°”å€™æ•°æ®",
        "expected_sources": ["FAOSTAT", "NOAA Climate Data", "IEA Energy Data"],
        "category": "ç®€çŸ­æµ‹è¯•"
    },
    {
        "id": 15,
        "name": "å¤–èµ„åœ¨åæŠ•èµ„åˆ†æ",
        "query": "æƒ³çœ‹çœ‹æœ€è¿‘å‡ å¹´å¤–èµ„ä¼ä¸šåœ¨ä¸­å›½çš„æŠ•èµ„æƒ…å†µ,å“ªäº›è¡Œä¸šæ›´å—é’ç",
        "expected_sources": ["Ministry of Commerce of China", "National Bureau of Statistics of China"],
        "category": "ç®€çŸ­æµ‹è¯•"
    },
    {
        "id": 16,
        "name": "äººæ°‘å¸æ±‡ç‡åˆ†æ",
        "query": "äººæ°‘å¸å¯¹ç¾å…ƒæ±‡ç‡æœ€è¿‘ä¸€å¹´çš„æ³¢åŠ¨æƒ…å†µ,ä»¥åŠå½±å“æ±‡ç‡çš„ä¸»è¦å› ç´ ",
        "expected_sources": ["People's Bank of China", "Alpha Vantage API"],
        "category": "ç®€çŸ­æµ‹è¯•"
    },
    {
        "id": 17,
        "name": "æ’’å“ˆæ‹‰ä»¥å—éæ´²è´«å›°ç ”ç©¶",
        "query": "æƒ³äº†è§£æ’’å“ˆæ‹‰ä»¥å—éæ´²åœ°åŒºçš„è´«å›°çŠ¶å†µæ”¹å–„äº†æ²¡æœ‰,æœ‰ä»€ä¹ˆæ•°æ®æ”¯æ’‘",
        "expected_sources": ["World Bank Open Data", "African Development Bank"],
        "category": "ç®€çŸ­æµ‹è¯•"
    },
    {
        "id": 18,
        "name": "ä¸­å›½ç”µå½±ç¥¨æˆ¿åˆ†æ",
        "query": "æ”¶é›†æ•´ç†ç›®å‰ä¸­å›½ç”µå½±ç¥¨æˆ¿å‰åçš„ç”µå½±çš„ç›¸å…³èµ„æ–™,æ¨ªå‘æ¯”è¾ƒå„ç”µå½±çš„ä¸»é¢˜ã€åˆ¶ä½œå…¬å¸ã€é¢˜æã€æ—¶é•¿ç­‰ç»´åº¦,å¹¶ä¸ºæˆ‘è¯„ä¼°å‡ºæœ€æœ‰å¯èƒ½åœ¨æœªæ¥å®ç°é«˜ç¥¨æˆ¿çš„ç”µå½±ç±»å‹",
        "expected_sources": ["National Bureau of Statistics of China", "Ministry of Commerce of China"],
        "category": "ç®€çŸ­æµ‹è¯•"
    },
    {
        "id": 19,
        "name": "ç”µå­ç«æŠ€èµ›äº‹æ•°æ®ï¼ˆè´Ÿé¢æµ‹è¯•ï¼‰",
        "query": "æˆ‘æƒ³åˆ†æè¿‘ä¸‰å¹´å…¨çƒä¸»è¦ç”µç«èµ›äº‹çš„è§‚ä¼—æ•°æ®å’Œå¥–é‡‘åˆ†å¸ƒ,æ¯”å¦‚è‹±é›„è”ç›Ÿã€DOTA2è¿™äº›æ¯”èµ›",
        "expected_sources": [],
        "category": "è´Ÿé¢æµ‹è¯•",
        "expected_behavior": "åº”è¿”å›'æœªæ‰¾åˆ°åŒ¹é…çš„æ•°æ®æº'æˆ–å»ºè®®æ›´å®½æ³›çš„æœç´¢è¯"
    },
    {
        "id": 20,
        "name": "ç«æ˜Ÿæ¢æµ‹æ°”è±¡æ•°æ®ï¼ˆè´Ÿé¢æµ‹è¯•ï¼‰",
        "query": "éœ€è¦ç«æ˜Ÿè¡¨é¢çš„æ¸©åº¦ã€æ°”å‹å’Œé£é€Ÿç­‰æ°”è±¡è§‚æµ‹æ•°æ®,ç”¨äºç ”ç©¶ç«æ˜Ÿæ°”å€™",
        "expected_sources": [],
        "category": "è´Ÿé¢æµ‹è¯•",
        "expected_behavior": "åº”æ˜ç¡®è¿”å›'æœªæ‰¾åˆ°ç›¸å…³æ•°æ®æº',ä¸åº”æ¨èåœ°çƒæ°”å€™æ•°æ®"
    }
]


# å…¨å±€ä¼šè¯ç®¡ç†
_mcp_session = None


class MCPSession:
    """MCPä¼šè¯ç®¡ç†"""
    def __init__(self, server_url: str):
        self.server_url = server_url
        self.session = requests.Session()
        self.session.headers.update({
            "Content-Type": "application/json",
            "Accept": "application/json, text/event-stream"
        })
        # å®¢æˆ·ç«¯ç”Ÿæˆsession ID
        self.session_id = str(uuid.uuid4())

    def initialize(self) -> bool:
        """åˆå§‹åŒ–MCPä¼šè¯"""
        try:
            payload = {
                "jsonrpc": "2.0",
                "id": 1,
                "method": "initialize",
                "params": {
                    "protocolVersion": "2024-11-05",
                    "capabilities": {},
                    "clientInfo": {"name": "test_client", "version": "1.0"}
                }
            }

            response = self.session.post(self.server_url, json=payload, timeout=30)

            if response.status_code == 200:
                # FastMCPè¿”å›session IDåœ¨å“åº”å¤´ä¸­
                session_id_from_header = response.headers.get('mcp-session-id')
                if session_id_from_header:
                    self.session_id = session_id_from_header
                    return True
                # å¦‚æœæ²¡æœ‰mcp-session-idå¤´ï¼Œå°è¯•ä½¿ç”¨å®¢æˆ·ç«¯ç”Ÿæˆçš„ID
                return True

            return False

        except Exception as e:
            print(f"åˆå§‹åŒ–å¤±è´¥: {e}")
            return False

    def call_tool(self, tool_name: str, arguments: dict) -> Tuple[str, float, str]:
        """è°ƒç”¨MCPå·¥å…·"""
        try:
            # FastMCPéœ€è¦åœ¨è¯·æ±‚å¤´ä¸­åŒ…å«session ID
            headers = {
                "Content-Type": "application/json",
                "Accept": "application/json, text/event-stream"
            }
            if self.session_id:
                headers["mcp-session-id"] = self.session_id

            payload = {
                "jsonrpc": "2.0",
                "id": str(uuid.uuid4()),
                "method": "tools/call",
                "params": {
                    "name": tool_name,
                    "arguments": arguments
                }
            }

            start_time = time.time()
            response = self.session.post(self.server_url, json=payload, headers=headers, timeout=120)
            # å¼ºåˆ¶ä½¿ç”¨UTF-8ç¼–ç ï¼Œé¿å…requestsä½¿ç”¨ISO-8859-1å¯¼è‡´ä¸­æ–‡ä¹±ç 
            response.encoding = 'utf-8'
            elapsed = time.time() - start_time

            if response.status_code != 200:
                return "", elapsed, f"HTTP {response.status_code}: {response.text[:200]}"

            # è§£æSSEå“åº”
            result_text = ""
            for line in response.text.split('\n'):
                if line.startswith('data:'):
                    try:
                        data = json.loads(line[5:].strip())
                        if 'result' in data:
                            result = data['result']
                            if isinstance(result, dict):
                                if 'content' in result:
                                    for content in result['content']:
                                        if isinstance(content, dict) and content.get('type') == 'text':
                                            result_text += content.get('text', '')
                                elif 'result' in result:
                                    result_text = str(result['result'])
                            elif isinstance(result, str):
                                result_text = result
                    except json.JSONDecodeError:
                        continue

            return result_text, elapsed, ""

        except requests.Timeout:
            return "", 0.0, "è¯·æ±‚è¶…æ—¶ï¼ˆ120ç§’ï¼‰"
        except Exception as e:
            return "", 0.0, f"é”™è¯¯: {type(e).__name__} - {str(e)}"


def get_mcp_session() -> MCPSession:
    """è·å–æˆ–åˆ›å»ºMCPä¼šè¯"""
    global _mcp_session
    if _mcp_session is None:
        _mcp_session = MCPSession("http://localhost:8001/mcp")
        if not _mcp_session.initialize():
            print("âš ï¸ è­¦å‘Š: MCPä¼šè¯åˆå§‹åŒ–å¤±è´¥ï¼Œå°è¯•ç»§ç»­...")
    return _mcp_session


def call_mcp_tool(query: str) -> Tuple[str, float, str]:
    """
    é€šè¿‡HTTPè°ƒç”¨MCPæœåŠ¡å™¨å·¥å…·

    Returns:
        (response_text, elapsed_time, error_message)
    """
    try:
        session = get_mcp_session()
        # FastMCPå·¥å…·å‚æ•°éœ€è¦åŒ…è£…åœ¨paramsä¸­
        return session.call_tool("datasource_search_llm_agent", {"params": {"query": query}})
    except Exception as e:
        return "", 0.0, f"é”™è¯¯: {type(e).__name__} - {str(e)}"


def extract_datasources_from_response(response: str) -> List[str]:
    """ä»å“åº”ä¸­æå–æ¨èçš„æ•°æ®æºåç§°"""
    datasources = []

    # ç®€å•çš„æå–é€»è¾‘ï¼šæŸ¥æ‰¾è¡¨æ ¼ä¸­çš„æ•°æ®æºåç§°
    # è¿™é‡Œä½¿ç”¨ç®€å•çš„å­—ç¬¦ä¸²åŒ¹é…
    lines = response.split('\n')
    for line in lines:
        # æŸ¥æ‰¾è¡¨æ ¼è¡Œï¼ˆåŒ…å«|ç¬¦å·ï¼‰
        if '|' in line and not line.strip().startswith('|---'):
            # æå–åç§°åˆ—ï¼ˆé€šå¸¸æ˜¯ç¬¬äºŒåˆ—ï¼‰
            parts = [p.strip() for p in line.split('|')]
            if len(parts) > 2:
                # åç§°å¯èƒ½åŒ…å«<br>æ ‡ç­¾
                name = parts[2].replace('<br>', ' ').strip()
                if name and name != 'åç§°' and name != '...':
                    datasources.append(name)

    return datasources


def run_test_case(test_case: Dict) -> Dict:
    """è¿è¡Œå•ä¸ªæµ‹è¯•ç”¨ä¾‹"""
    print(f"è¿è¡Œæµ‹è¯• {test_case['id']}: {test_case['name']}...")

    response, elapsed, error = call_mcp_tool(test_case['query'])

    if error:
        return {
            "test_id": test_case['id'],
            "name": test_case['name'],
            "category": test_case['category'],
            "status": "ERROR",
            "error": error,
            "elapsed_time": 0.0
        }

    # æå–æ¨èçš„æ•°æ®æº
    recommended = extract_datasources_from_response(response)
    expected = test_case.get('expected_sources', [])

    # è¯„ä¼°ç»“æœ
    if test_case['category'] == 'è´Ÿé¢æµ‹è¯•':
        # è´Ÿé¢æµ‹è¯•ï¼šä¸åº”æ‰¾åˆ°æ•°æ®æº
        status = "PASS" if len(recommended) == 0 or "æœªæ‰¾åˆ°" in response else "FAIL"
    else:
        # æ­£é¢æµ‹è¯•ï¼šæ£€æŸ¥æ˜¯å¦æ¨èäº†æœŸæœ›çš„æ•°æ®æº
        matches = sum(1 for exp in expected if any(exp.lower() in rec.lower() for rec in recommended))
        coverage = matches / len(expected) if expected else 0
        status = "PASS" if coverage >= 0.5 else "PARTIAL" if coverage > 0 else "FAIL"

    return {
        "test_id": test_case['id'],
        "name": test_case['name'],
        "category": test_case['category'],
        "status": status,
        "query": test_case['query'],
        "expected_sources": expected,
        "recommended_sources": recommended,
        "response": response,
        "elapsed_time": elapsed,
        "coverage": matches / len(expected) if expected else None
    }


def generate_report(results: List[Dict], output_file: Path):
    """ç”ŸæˆMarkdownæ ¼å¼çš„æµ‹è¯•æŠ¥å‘Š"""

    # ç»Ÿè®¡ç»“æœ
    total = len(results)
    passed = sum(1 for r in results if r['status'] == 'PASS')
    partial = sum(1 for r in results if r['status'] == 'PARTIAL')
    failed = sum(1 for r in results if r['status'] == 'FAIL')
    errors = sum(1 for r in results if r['status'] == 'ERROR')

    avg_time = sum(r['elapsed_time'] for r in results) / total if total > 0 else 0

    # ç”ŸæˆæŠ¥å‘Š
    lines = []
    lines.append("# DataSource Hub MCP æµ‹è¯•æŠ¥å‘Š\n")
    lines.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    lines.append(f"**MCPæœåŠ¡å™¨**: DataSource Hub Agent v0.1.0\n")
    lines.append("")

    # æ€»ç»“
    lines.append("## æµ‹è¯•æ€»ç»“\n")
    lines.append(f"- **æ€»æµ‹è¯•æ•°**: {total}")
    lines.append(f"- **é€šè¿‡**: {passed} ({passed/total*100:.1f}%)")
    lines.append(f"- **éƒ¨åˆ†é€šè¿‡**: {partial} ({partial/total*100:.1f}%)")
    lines.append(f"- **å¤±è´¥**: {failed} ({failed/total*100:.1f}%)")
    lines.append(f"- **é”™è¯¯**: {errors} ({errors/total*100:.1f}%)")
    lines.append(f"- **å¹³å‡å“åº”æ—¶é—´**: {avg_time:.2f}ç§’\n")

    # æŒ‰ç±»åˆ«ç»Ÿè®¡
    lines.append("## åˆ†ç±»ç»Ÿè®¡\n")
    categories = {}
    for r in results:
        cat = r['category']
        if cat not in categories:
            categories[cat] = {'total': 0, 'pass': 0}
        categories[cat]['total'] += 1
        if r['status'] == 'PASS':
            categories[cat]['pass'] += 1

    lines.append("| ç±»åˆ« | é€šè¿‡ç‡ | é€šè¿‡/æ€»æ•° |")
    lines.append("|------|--------|-----------|")
    for cat, stats in categories.items():
        rate = stats['pass'] / stats['total'] * 100
        lines.append(f"| {cat} | {rate:.1f}% | {stats['pass']}/{stats['total']} |")
    lines.append("")

    # è¯¦ç»†ç»“æœ
    lines.append("## è¯¦ç»†æµ‹è¯•ç»“æœ\n")

    for result in results:
        lines.append(f"### Test Case {result['test_id']}: {result['name']}\n")
        lines.append(f"**çŠ¶æ€**: {'âœ… PASS' if result['status'] == 'PASS' else 'âš ï¸ PARTIAL' if result['status'] == 'PARTIAL' else 'âŒ FAIL' if result['status'] == 'FAIL' else 'ğŸ”´ ERROR'}")
        lines.append(f"**ç±»åˆ«**: {result['category']}")
        lines.append(f"**å“åº”æ—¶é—´**: {result['elapsed_time']:.2f}ç§’\n")

        if result['status'] == 'ERROR':
            lines.append(f"**é”™è¯¯ä¿¡æ¯**: {result['error']}\n")
        else:
            lines.append("**æŸ¥è¯¢**:")
            lines.append("```")
            lines.append(result['query'])
            lines.append("```\n")

            if result.get('expected_sources'):
                lines.append("**æœŸæœ›æ•°æ®æº**:")
                for src in result['expected_sources']:
                    lines.append(f"- {src}")
                lines.append("")

            if result.get('recommended_sources'):
                lines.append("**æ¨èæ•°æ®æº**:")
                for src in result['recommended_sources']:
                    # æ£€æŸ¥æ˜¯å¦åŒ¹é…æœŸæœ›
                    matched = any(exp.lower() in src.lower() for exp in result.get('expected_sources', []))
                    prefix = "âœ…" if matched else "  "
                    lines.append(f"{prefix} {src}")
                lines.append("")

            if result.get('coverage') is not None:
                lines.append(f"**è¦†ç›–ç‡**: {result['coverage']*100:.1f}%\n")

            lines.append("<details>")
            lines.append("<summary>å®Œæ•´å“åº”</summary>\n")
            lines.append("```")
            lines.append(result['response'][:2000] + "..." if len(result['response']) > 2000 else result['response'])
            lines.append("```")
            lines.append("</details>\n")

        lines.append("---\n")

    # å†™å…¥æ–‡ä»¶
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write('\n'.join(lines))

    print(f"\næµ‹è¯•æŠ¥å‘Šå·²ç”Ÿæˆ: {output_file}")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("DataSource Hub MCP è‡ªåŠ¨åŒ–æµ‹è¯•")
    print("=" * 60)
    print(f"æµ‹è¯•ç”¨ä¾‹æ€»æ•°: {len(TEST_CASES)}")
    print("å¼€å§‹æµ‹è¯•...\n")

    results = []

    for i, test_case in enumerate(TEST_CASES, 1):
        print(f"\n[{i}/{len(TEST_CASES)}] ", end="")
        result = run_test_case(test_case)
        results.append(result)

        # æ˜¾ç¤ºç®€å•ç»“æœ
        status_icon = {
            'PASS': 'âœ…',
            'PARTIAL': 'âš ï¸',
            'FAIL': 'âŒ',
            'ERROR': 'ğŸ”´'
        }
        print(f"{status_icon[result['status']]} {result['status']} ({result['elapsed_time']:.1f}s)")

        # é¿å…è¯·æ±‚è¿‡å¿«
        time.sleep(1)

    # ç”ŸæˆæŠ¥å‘Š
    print("\n" + "=" * 60)
    print("ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š...")
    output_file = Path(__file__).parent / f"test_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
    generate_report(results, output_file)

    # æ˜¾ç¤ºæ€»ç»“
    passed = sum(1 for r in results if r['status'] == 'PASS')
    print(f"\næµ‹è¯•å®Œæˆ! é€šè¿‡ç‡: {passed}/{len(results)} ({passed/len(results)*100:.1f}%)")


if __name__ == "__main__":
    main()
