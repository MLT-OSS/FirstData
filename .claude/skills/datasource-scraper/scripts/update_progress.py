#!/usr/bin/env python3
"""
è‡ªåŠ¨ç»Ÿè®¡æ•°æ®æºå¹¶æ›´æ–°æ‰€æœ‰è¿›åº¦æ–‡ä»¶

åŠŸèƒ½ï¼š
1. ç»Ÿè®¡å„åˆ†ç±»ä¸‹çš„æ•°æ®æºæ•°é‡
2. è®¡ç®—è´¨é‡è¯„åˆ†
3. æ›´æ–° README.md ä¸­çš„æ‰€æœ‰è¿›åº¦ä¿¡æ¯
4. ç”Ÿæˆè¯¦ç»†çš„ç»Ÿè®¡æŠ¥å‘Š

ä½¿ç”¨æ–¹æ³•ï¼š
    python .claude/skills/datasource-scraper/scripts/update_progress.py
    python .claude/skills/datasource-scraper/scripts/update_progress.py --dry-run  # ä»…æ˜¾ç¤ºå˜æ›´ï¼Œä¸å®é™…ä¿®æ”¹
    python .claude/skills/datasource-scraper/scripts/update_progress.py --verbose  # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
"""

import json
import re
from pathlib import Path
from collections import defaultdict
from typing import Dict, List, Tuple
import argparse
import sys


class ProgressUpdater:
    """è¿›åº¦ç»Ÿè®¡å’Œæ›´æ–°å™¨"""

    def __init__(self, base_dir: Path, dry_run: bool = False, verbose: bool = False):
        self.base_dir = base_dir
        self.sources_dir = base_dir / "sources"
        self.dry_run = dry_run
        self.verbose = verbose

        # ç›®æ ‡æ–‡ä»¶è·¯å¾„
        self.readme_path = base_dir / "README.md"

        # ç»Ÿè®¡æ•°æ®
        self.stats = {
            'total': 0,
            'international': 0,
            'china': 0,
            'countries': 0,
            'academic': 0,
            'sectors': 0,
        }

        # æ•°æ®æºè¯¦ç»†åˆ—è¡¨
        self.datasources = {
            'international': [],
            'china': [],
            'countries': [],
            'academic': [],
            'sectors': [],
        }

        # è´¨é‡è¯„åˆ†
        self.quality_scores = []

    def log(self, message: str, force: bool = False):
        """è¾“å‡ºæ—¥å¿—"""
        if self.verbose or force:
            print(message)

    def scan_datasources(self):
        """æ‰«ææ‰€æœ‰æ•°æ®æºæ–‡ä»¶å¹¶ç»Ÿè®¡"""
        self.log("ğŸ” æ‰«ææ•°æ®æºæ–‡ä»¶...", force=True)

        for category in ['international', 'china', 'countries', 'academic', 'sectors']:
            category_dir = self.sources_dir / category
            if not category_dir.exists():
                continue

            json_files = list(category_dir.rglob("*.json"))
            self.stats[category] = len(json_files)

            self.log(f"  {category}: {len(json_files)} ä¸ªæ–‡ä»¶")

            # è¯»å–æ¯ä¸ªæ•°æ®æºçš„è¯¦ç»†ä¿¡æ¯
            for json_file in json_files:
                try:
                    with open(json_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)

                    # æå–ä¿¡æ¯
                    ds_info = {
                        'id': data.get('id', ''),
                        'name_zh': data.get('name', {}).get('zh', ''),
                        'name_en': data.get('name', {}).get('en', ''),
                        'authority': data.get('quality', {}).get('authority_level', 0),
                        'file_path': str(json_file.relative_to(self.base_dir))
                    }

                    # è®¡ç®—å¹³å‡è´¨é‡ï¼ˆåªä½¿ç”¨6ä¸ªæ ‡å‡†è¯„åˆ†å­—æ®µï¼‰
                    quality = data.get('quality', {})
                    if quality:
                        # æ ‡å‡†çš„6ä¸ªè´¨é‡è¯„åˆ†å­—æ®µ
                        quality_fields = [
                            'authority_level',
                            'methodology_transparency',
                            'update_timeliness',
                            'data_completeness',
                            'documentation_quality',
                            'citation_count'
                        ]
                        # åªæå–æ•°å€¼ç±»å‹çš„è´¨é‡è¯„åˆ†
                        scores = [
                            quality[field] for field in quality_fields
                            if field in quality and isinstance(quality[field], (int, float))
                        ]
                        if scores:
                            avg_quality = sum(scores) / len(scores)
                            self.quality_scores.append(avg_quality)
                            ds_info['avg_quality'] = avg_quality

                    self.datasources[category].append(ds_info)

                except Exception as e:
                    self.log(f"  âš ï¸  è¯»å–æ–‡ä»¶å¤±è´¥: {json_file} - {e}")

        self.stats['total'] = sum(self.stats.values())

        self.log(f"\nâœ… æ‰«æå®Œæˆï¼Œå…±æ‰¾åˆ° {self.stats['total']} ä¸ªæ•°æ®æº", force=True)
        return self.stats

    def calculate_progress(self) -> Dict[str, float]:
        """è®¡ç®—è¿›åº¦ç™¾åˆ†æ¯”"""
        # ç›®æ ‡æ•°é‡ï¼ˆä»PRDæˆ–ROADMAPä¸­è·å–ï¼‰
        targets = {
            'total': 950,
            'international': 100,
            'china': 488,
            'countries': 200,
            'academic': 50,
            'sectors': 150,
        }

        progress = {}
        for key, current in self.stats.items():
            target = targets[key]
            progress[key] = round((current / target) * 100) if target > 0 else 0

        return progress

    def calculate_avg_quality(self) -> float:
        """è®¡ç®—å¹³å‡è´¨é‡è¯„åˆ†"""
        if not self.quality_scores:
            return 5.0
        return round(sum(self.quality_scores) / len(self.quality_scores), 1)

    def generate_report(self) -> str:
        """ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š"""
        progress = self.calculate_progress()
        avg_quality = self.calculate_avg_quality()

        report = []
        report.append("=" * 60)
        report.append("ğŸ“Š æ•°æ®æºç»Ÿè®¡æŠ¥å‘Š")
        report.append("=" * 60)
        report.append("")
        report.append(f"æ€»æ•°æ®æº: {self.stats['total']} / 950+ ({progress['total']}%)")
        report.append(f"å›½é™…ç»„ç»‡: {self.stats['international']} / 100+ ({progress['international']}%)")
        report.append(f"ä¸­å›½æ•°æ®æº: {self.stats['china']} / 488 ({progress['china']}%)")
        report.append(f"å„å›½å®˜æ–¹: {self.stats['countries']} / 200+ ({progress['countries']}%)")
        report.append(f"å­¦æœ¯ç ”ç©¶: {self.stats['academic']} / 50+ ({progress['academic']}%)")
        report.append(f"è¡Œä¸šé¢†åŸŸ: {self.stats['sectors']} / 150+ ({progress['sectors']}%)")
        report.append("")
        report.append(f"å¹³å‡è´¨é‡è¯„åˆ†: {avg_quality}/5.0")
        report.append("")
        report.append("=" * 60)

        return "\n".join(report)

    def update_readme_badges(self, content: str) -> str:
        """æ›´æ–°READMEé¡¶éƒ¨å¾½ç« """
        progress = self.calculate_progress()

        # æ›´æ–°æ•°æ®æºæ•°é‡å¾½ç« 
        pattern_sources = r'\[\!\[Data Sources\]\(https://img\.shields\.io/badge/Data%20Sources-\d+%2F950\+-blue\.svg\)\]'
        replacement_sources = f'[![Data Sources](https://img.shields.io/badge/Data%20Sources-{self.stats["total"]}%2F950+-blue.svg)]'
        content = re.sub(pattern_sources, replacement_sources, content)

        # æ›´æ–°è¿›åº¦å¾½ç« 
        pattern_progress = r'\[\!\[Progress\]\(https://img\.shields\.io/badge/Progress-\d+%25-yellow\.svg\)\]'
        replacement_progress = f'[![Progress](https://img.shields.io/badge/Progress-{progress["total"]}%25-yellow.svg)]'
        content = re.sub(pattern_progress, replacement_progress, content)

        # æ›´æ–°è´¨é‡è¯„åˆ†å¾½ç« 
        avg_quality = self.calculate_avg_quality()
        pattern_quality = r'\[\!\[Quality Rating\]\(https://img\.shields\.io/badge/Avg%20Quality-[\d.]+%2F5\.0-brightgreen\.svg\)\]'
        replacement_quality = f'[![Quality Rating](https://img.shields.io/badge/Avg%20Quality-{avg_quality}%2F5.0-brightgreen.svg)]'
        content = re.sub(pattern_quality, replacement_quality, content)

        return content

    def update_readme_stats_table(self, content: str) -> str:
        """æ›´æ–°æ€»ä½“ç»Ÿè®¡è¡¨æ ¼"""
        progress = self.calculate_progress()

        # æ„å»ºæ–°çš„è¡¨æ ¼å†…å®¹
        table_lines = [
            "| æŒ‡æ ‡ | å½“å‰/ç›®æ ‡ | è¿›åº¦ |",
            "|------|-----------|------|",
            f"| **æ€»æ•°æ®æº** | {self.stats['total']} / 950+ | {progress['total']}% |",
            f"| **å›½é™…ç»„ç»‡** | {self.stats['international']} / 100+ | {progress['international']}% |",
            f"| **å„å›½å®˜æ–¹** | {self.stats['countries']} / 200+ | {progress['countries']}% |",
            f"| **ä¸­å›½æ•°æ®æº** | {self.stats['china']} / 488 | {progress['china']}% |",
            f"| **å­¦æœ¯ç ”ç©¶** | {self.stats['academic']} / 50+ | {progress['academic']}% |",
            f"| **è¡Œä¸šé¢†åŸŸ** | {self.stats['sectors']} / 150+ | {progress['sectors']}% |",
        ]

        new_table = "\n".join(table_lines)

        # æ›¿æ¢è¡¨æ ¼ï¼ˆä»"| æŒ‡æ ‡ | å½“å‰/ç›®æ ‡ | è¿›åº¦ |"å¼€å§‹ï¼Œåˆ°"| **è¡Œä¸šé¢†åŸŸ**"ç»“æŸï¼‰
        pattern = r'\| æŒ‡æ ‡ \| å½“å‰/ç›®æ ‡ \| è¿›åº¦ \|.*?\| \*\*è¡Œä¸šé¢†åŸŸ\*\* \|[^\n]*'
        content = re.sub(pattern, new_table, content, flags=re.DOTALL)

        return content

    def update_readme_datasource_lists(self, content: str) -> str:
        """æ›´æ–°å·²å®Œæˆæ•°æ®æºåˆ—è¡¨"""
        # æ›´æ–°å›½é™…ç»„ç»‡
        content = self._update_category_list(
            content,
            'international',
            r'#### ğŸŒ å›½é™…ç»„ç»‡ \((\d+)ä¸ª\)',
            f'#### ğŸŒ å›½é™…ç»„ç»‡ ({self.stats["international"]}ä¸ª)'
        )

        # æ›´æ–°ä¸­å›½æ•°æ®æº
        content = self._update_category_list(
            content,
            'china',
            r'#### ğŸ‡¨ğŸ‡³ ä¸­å›½æ•°æ®æº \((\d+)ä¸ª\)',
            f'#### ğŸ‡¨ğŸ‡³ ä¸­å›½æ•°æ®æº ({self.stats["china"]}ä¸ª)'
        )

        # æ›´æ–°å„å›½å®˜æ–¹
        content = self._update_category_list(
            content,
            'countries',
            r'#### ğŸŒ å„å›½å®˜æ–¹ \((\d+)ä¸ª\)',
            f'#### ğŸŒ å„å›½å®˜æ–¹ ({self.stats["countries"]}ä¸ª)'
        )

        # æ›´æ–°å­¦æœ¯ç ”ç©¶
        content = self._update_category_list(
            content,
            'academic',
            r'#### ğŸ“ å­¦æœ¯ç ”ç©¶ \((\d+)ä¸ª\)',
            f'#### ğŸ“ å­¦æœ¯ç ”ç©¶ ({self.stats["academic"]}ä¸ª)'
        )

        # æ›´æ–°è¡Œä¸šé¢†åŸŸ
        content = self._update_category_list(
            content,
            'sectors',
            r'#### ğŸ­ è¡Œä¸šé¢†åŸŸ \((\d+)ä¸ª\)',
            f'#### ğŸ­ è¡Œä¸šé¢†åŸŸ ({self.stats["sectors"]}ä¸ª)'
        )

        return content

    def _update_category_list(self, content: str, category: str,
                             header_pattern: str, new_header: str) -> str:
        """æ›´æ–°å•ä¸ªåˆ†ç±»çš„æ•°æ®æºåˆ—è¡¨"""
        # åªæ›´æ–°æ ‡é¢˜ä¸­çš„æ•°å­—
        content = re.sub(header_pattern, new_header, content)
        return content

    def update_readme_project_status(self, content: str) -> str:
        """æ›´æ–°é¡¹ç›®çŠ¶æ€è¡¨æ ¼"""
        progress = self.calculate_progress()
        avg_quality = self.calculate_avg_quality()

        from datetime import datetime
        today = datetime.now().strftime('%Y-%m-%d')

        # æ„å»ºæ–°çš„é¡¹ç›®çŠ¶æ€è¡¨æ ¼
        status_lines = [
            "| æŒ‡æ ‡ | çŠ¶æ€ |",
            "|------|------|",
            "| **å½“å‰é‡Œç¨‹ç¢‘** | M0 å®Œæˆ âœ… / M1 è¿›è¡Œä¸­ ğŸš§ |",
            f"| **æ€»ä½“è¿›åº¦** | {self.stats['total']} / 950+ ({progress['total']}%) |",
            f"| **å®Œæˆåº¦** | å›½é™…ç»„ç»‡ {progress['international']}%ã€ä¸­å›½ {progress['china']}%ã€å­¦æœ¯ {progress['academic']}% |",
            f"| **æœ€è¿‘æ›´æ–°** | {today} |",
            f"| **è´¨é‡è¯„åˆ†** | â­â­â­â­â­ ({avg_quality}/5.0) |",
        ]

        new_status = "\n".join(status_lines)

        # æ›¿æ¢é¡¹ç›®çŠ¶æ€è¡¨æ ¼
        pattern = r'## ğŸ“Š é¡¹ç›®çŠ¶æ€ \| Project Status\s*\n\s*\| æŒ‡æ ‡ \| çŠ¶æ€ \|.*?\| \*\*è´¨é‡è¯„åˆ†\*\* \|[^\n]*'
        replacement = f"## ğŸ“Š é¡¹ç›®çŠ¶æ€ | Project Status\n\n{new_status}"
        content = re.sub(pattern, replacement, content, flags=re.DOTALL)

        return content

    def update_readme(self) -> bool:
        """æ›´æ–° README.md"""
        self.log("ğŸ“ æ›´æ–° README.md...", force=True)

        if not self.readme_path.exists():
            self.log("âŒ README.md ä¸å­˜åœ¨", force=True)
            return False

        # è¯»å–åŸå†…å®¹
        with open(self.readme_path, 'r', encoding='utf-8') as f:
            original_content = f.read()

        # æ‰§è¡Œå„é¡¹æ›´æ–°
        content = original_content
        content = self.update_readme_badges(content)
        content = self.update_readme_stats_table(content)
        content = self.update_readme_datasource_lists(content)
        content = self.update_readme_project_status(content)

        # æ£€æŸ¥æ˜¯å¦æœ‰å˜æ›´
        if content == original_content:
            self.log("  â„¹ï¸  æ²¡æœ‰éœ€è¦æ›´æ–°çš„å†…å®¹", force=True)
            return False

        if self.dry_run:
            self.log("  ğŸ” [DRY RUN] æ£€æµ‹åˆ°å˜æ›´ï¼Œä½†ä¸ä¼šå®é™…ä¿®æ”¹æ–‡ä»¶", force=True)
            # æ˜¾ç¤ºå·®å¼‚
            self._show_diff(original_content, content)
            return True

        # å†™å…¥æ–°å†…å®¹
        with open(self.readme_path, 'w', encoding='utf-8') as f:
            f.write(content)

        self.log("  âœ… README.md å·²æ›´æ–°", force=True)
        return True

    def _show_diff(self, old: str, new: str):
        """æ˜¾ç¤ºæ–‡ä»¶å·®å¼‚ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        old_lines = old.split('\n')
        new_lines = new.split('\n')

        changes = []
        for i, (old_line, new_line) in enumerate(zip(old_lines, new_lines), 1):
            if old_line != new_line:
                changes.append(f"  Line {i}:")
                changes.append(f"    - {old_line[:80]}")
                changes.append(f"    + {new_line[:80]}")

        if changes:
            self.log("\n  å˜æ›´é¢„è§ˆ:")
            self.log("\n".join(changes[:20]))  # åªæ˜¾ç¤ºå‰20ä¸ªå˜æ›´
            if len(changes) > 20:
                self.log(f"  ... è¿˜æœ‰ {len(changes) - 20} å¤„å˜æ›´")

    def run(self) -> int:
        """æ‰§è¡Œå®Œæ•´çš„æ›´æ–°æµç¨‹"""
        try:
            # 1. æ‰«ææ•°æ®æº
            self.scan_datasources()

            # 2. ç”ŸæˆæŠ¥å‘Š
            report = self.generate_report()
            print("\n" + report)

            # 3. æ›´æ–° README
            readme_updated = self.update_readme()

            # 4. æ€»ç»“
            print("\n" + "=" * 60)
            if self.dry_run:
                print("ğŸ” DRY RUN æ¨¡å¼ - æœªè¿›è¡Œå®é™…ä¿®æ”¹")
            else:
                print("âœ… æ›´æ–°å®Œæˆ")

            if readme_updated:
                print(f"ğŸ“ README.md: {'æ£€æµ‹åˆ°å˜æ›´' if self.dry_run else 'å·²æ›´æ–°'}")
            else:
                print("â„¹ï¸  æ‰€æœ‰æ–‡ä»¶å·²æ˜¯æœ€æ–°çŠ¶æ€")

            print("=" * 60)

            return 0

        except Exception as e:
            print(f"\nâŒ é”™è¯¯: {e}", file=sys.stderr)
            if self.verbose:
                import traceback
                traceback.print_exc()
            return 1


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="è‡ªåŠ¨ç»Ÿè®¡æ•°æ®æºå¹¶æ›´æ–°æ‰€æœ‰è¿›åº¦æ–‡ä»¶",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  %(prog)s                    # ç»Ÿè®¡å¹¶æ›´æ–°æ‰€æœ‰æ–‡ä»¶
  %(prog)s --dry-run          # ä»…æ˜¾ç¤ºå˜æ›´ï¼Œä¸å®é™…ä¿®æ”¹
  %(prog)s --verbose          # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        """
    )

    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='ä»…æ˜¾ç¤ºå°†è¦è¿›è¡Œçš„å˜æ›´ï¼Œä¸å®é™…ä¿®æ”¹æ–‡ä»¶'
    )

    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='æ˜¾ç¤ºè¯¦ç»†çš„æ‰§è¡Œä¿¡æ¯'
    )

    parser.add_argument(
        '--base-dir',
        type=Path,
        default=Path.cwd(),
        help='é¡¹ç›®æ ¹ç›®å½•è·¯å¾„ï¼ˆé»˜è®¤ï¼šå½“å‰ç›®å½•ï¼‰'
    )

    args = parser.parse_args()

    # åˆ›å»ºæ›´æ–°å™¨å¹¶è¿è¡Œ
    updater = ProgressUpdater(
        base_dir=args.base_dir,
        dry_run=args.dry_run,
        verbose=args.verbose
    )

    return updater.run()


if __name__ == '__main__':
    sys.exit(main())
