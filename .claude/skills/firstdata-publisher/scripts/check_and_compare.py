#!/usr/bin/env python3
"""
æ•°æ®æºæ–‡æ¡£æ£€æŸ¥å’Œå¯¹æ¯”å·¥å…·
1. æ‰«æå®é™…çš„JSONæ–‡ä»¶
2. æ‰«ææ–‡æ¡£ä¸­çš„ç»Ÿè®¡ä¿¡æ¯
3. å¯¹æ¯”å·®å¼‚
4. ç”Ÿæˆæ›´æ–°æŠ¥å‘Š
"""

import json
import re
from collections import defaultdict
from pathlib import Path


class DataSourceChecker:
    def __init__(self):
        self.actual_sources = {}  # å®é™…çš„JSONæ–‡ä»¶
        self.doc_entries = {}  # æ–‡æ¡£ä¸­çš„æ¡ç›®
        self.doc_stats = {}  # æ–‡æ¡£ä¸­çš„ç»Ÿè®¡æ•°å­—

    def scan_actual_sources(self):
        """æ‰«æå®é™…çš„JSONæ–‡ä»¶"""
        print("=" * 80)
        print("æ­¥éª¤1: æ‰«æå®é™…æ•°æ®æºæ–‡ä»¶")
        print("=" * 80)

        sources_dir = Path("src/firstdata/sources")
        json_files = list(sources_dir.rglob("*.json"))

        by_category = defaultdict(list)
        by_subcategory = defaultdict(lambda: defaultdict(list))

        for json_file in sorted(json_files):
            try:
                with open(json_file, encoding="utf-8") as f:
                    data = json.load(f)

                # æå–å…³é”®ä¿¡æ¯
                info = {
                    "id": data.get("id", ""),
                    "filename_id": json_file.stem,  # ä»æ–‡ä»¶åæå–IDï¼Œç”¨äºåŒ¹é…
                    "name_en": data.get("name", {}).get("en", ""),
                    "name_zh": data.get("name", {}).get("zh", ""),
                    "authority": data.get("authority_level", ""),
                    "has_api": data.get("api_url") is not None,
                    "access_level": "open" if data.get("api_url") else "registration",
                    "update_frequency": data.get("update_frequency", ""),
                    "data_content_count": len(data.get("data_content", {}).get("zh", [])),
                    "path": str(json_file.relative_to("src/firstdata/sources")),
                }

                # ç¡®å®šåˆ†ç±»
                parts = json_file.parts
                if "international" in parts:
                    category = "international"
                    subcategory = parts[parts.index("international") + 1]
                elif "china" in parts:
                    category = "china"
                    subcategory = parts[parts.index("china") + 1]
                elif "countries" in parts:
                    category = "countries"
                    subcategory = parts[parts.index("countries") + 1]
                elif "academic" in parts:
                    category = "academic"
                    subcategory = parts[parts.index("academic") + 1]
                elif "sectors" in parts:
                    category = "sectors"
                    subcategory = parts[parts.index("sectors") + 1]
                else:
                    continue

                info["category"] = category
                info["subcategory"] = subcategory

                by_category[category].append(info)
                by_subcategory[category][subcategory].append(info)

            except Exception as e:
                print(f"  âš ï¸  é”™è¯¯: {json_file}: {e}")

        self.actual_sources = {
            "total": len(json_files),
            "by_category": {cat: len(sources) for cat, sources in by_category.items()},
            "by_subcategory": dict(by_subcategory),
            "all": by_category,
        }

        print(f"\nâœ… æ‰¾åˆ° {len(json_files)} ä¸ªJSONæ–‡ä»¶")
        for category, count in sorted(self.actual_sources["by_category"].items()):
            print(f"   {category:15s}: {count:3d} ä¸ª")

        return self.actual_sources

    def scan_docs(self):
        """æ‰«ææ–‡æ¡£ä¸­çš„ç»Ÿè®¡å’Œæ¡ç›®"""
        print("\n" + "=" * 80)
        print("æ­¥éª¤2: æ‰«ææ–‡æ¡£ä¸­çš„ç»Ÿè®¡ä¿¡æ¯")
        print("=" * 80)

        docs_to_check = {
            "international": "src/firstdata/sources/international/README.md",
            "china": "src/firstdata/sources/china/README.md",
            "countries": "src/firstdata/sources/countries/README.md",
            "academic": "src/firstdata/sources/academic/README.md",
            "sectors": "src/firstdata/sources/sectors/README.md",
            "main_readme": "README.md",
        }

        self.doc_entries = defaultdict(lambda: defaultdict(set))
        self.doc_stats = {}

        # æ‰«æå„åˆ†ç±»READMEä¸­çš„æ¡ç›®
        for category in ["international", "china", "countries", "academic", "sectors"]:
            readme_path = docs_to_check[category]
            if not Path(readme_path).exists():
                print(f"  âš ï¸  {readme_path} ä¸å­˜åœ¨")
                continue

            with open(readme_path, encoding="utf-8") as f:
                content = f.read()

            # æŸ¥æ‰¾æ‰€æœ‰æ•°æ®æºIDï¼ˆåœ¨æ–‡ä»¶é“¾æ¥ä¸­ï¼‰
            # åŒ¹é…æ¨¡å¼: [filename.json](path/to/file.json)
            pattern = r"\[([^\]]+\.json)\]\(([^\)]+)\)"
            matches = re.findall(pattern, content)

            for _filename, filepath in matches:
                # ä»filepathæå–IDï¼ˆé€šå¸¸æ˜¯æ–‡ä»¶åå»æ‰.jsonï¼‰
                source_id = Path(filepath).stem
                self.doc_entries[category]["found"].add(source_id)

            print(f"  {category:15s}: æ–‡æ¡£ä¸­æ‰¾åˆ° {len(self.doc_entries[category]['found'])} ä¸ªæ¡ç›®")

        # æ‰«æä¸»è¦æ–‡æ¡£ä¸­çš„ç»Ÿè®¡æ•°å­—
        self._scan_main_readme()

        # æ‰«æåˆ†ç±»READMEä¸­çš„ç»Ÿè®¡æ•°å­—
        self._scan_china_readme()
        self._scan_sectors_readme()
        self._scan_countries_readme()

        return self.doc_entries, self.doc_stats

    def _scan_main_readme(self):
        """æ‰«æä¸»READMEä¸­çš„ç»Ÿè®¡"""
        if not Path("README.md").exists():
            return

        with open("README.md", encoding="utf-8") as f:
            content = f.read()

        stats = {}

        # æå–æ€»æ•°ï¼ˆä»å¾½ç« ï¼‰
        # Badge æ ¼å¼: /badge/æ•°æ®æº-126%2F1000+
        badge_match = re.search(r"æ•°æ®æº-(\d+)%2F", content)
        if badge_match:
            stats["total_in_badge"] = int(badge_match.group(1))

        # æå–åˆ†ç±»ç»Ÿè®¡ï¼ˆä»è¡¨æ ¼ï¼‰
        # åŒ¹é…: | æ€»æ•°æ®æº | 127 / 950+ |
        total_match = re.search(r"\|\s*æ€»æ•°æ®æº\s*\|\s*(\d+)\s*/\s*(\d+)", content)
        if total_match:
            stats["total_in_table"] = int(total_match.group(1))

        # æå–å„åˆ†ç±»æ•°å­—
        category_patterns = {
            "international": r"\|\s*å›½é™…ç»„ç»‡\s*\|\s*(\d+)\s*/\s*(\d+)",
            "countries": r"\|\s*å„å›½å®˜æ–¹\s*\|\s*(\d+)\s*/\s*(\d+)",
            "china": r"\|\s*ä¸­å›½æ•°æ®æº\s*\|\s*(\d+)\s*/\s*(\d+)",
            "academic": r"\|\s*å­¦æœ¯ç ”ç©¶\s*\|\s*(\d+)\s*/\s*(\d+)",
            "sectors": r"\|\s*è¡Œä¸šé¢†åŸŸ\s*\|\s*(\d+)\s*/\s*(\d+)",
        }

        for category, pattern in category_patterns.items():
            match = re.search(pattern, content)
            if match:
                stats[f"{category}_in_table"] = int(match.group(1))

        self.doc_stats["main_readme"] = stats
        print("\n  README.md ç»Ÿè®¡:")
        print(f"    å¾½ç« æ€»æ•°: {stats.get('total_in_badge', 'N/A')}")
        print(f"    è¡¨æ ¼æ€»æ•°: {stats.get('total_in_table', 'N/A')}")

    def _scan_china_readme(self):
        """æ‰«æsrc/firstdata/sources/china/README.mdä¸­çš„ç»Ÿè®¡"""
        readme_path = "src/firstdata/sources/china/README.md"
        if not Path(readme_path).exists():
            return

        with open(readme_path, encoding="utf-8") as f:
            content = f.read()

        stats = {}

        # æå–å·²å®Œæˆæ•°é‡ï¼ˆç¬¬4è¡Œå·¦å³ï¼‰
        completed_match = re.search(r"\*\*å·²å®Œæˆ\*\*:\s*(\d+)ä¸ª", content)
        if completed_match:
            stats["completed"] = int(completed_match.group(1))

        # æå–å½“å‰å®Œæˆæ•°ï¼ˆè¿›åº¦æ¡ä¸­ï¼‰
        current_match = re.search(r"å½“å‰å®Œæˆ:\s*(\d+)\s*ä¸ª", content)
        if current_match:
            stats["current"] = int(current_match.group(1))

        self.doc_stats["china_readme"] = stats
        print("\n  src/firstdata/sources/china/README.md ç»Ÿè®¡:")
        print(f"    å·²å®Œæˆ: {stats.get('completed', 'N/A')} ä¸ª")

    def _scan_sectors_readme(self):
        """æ‰«æsrc/firstdata/sources/sectors/README.mdä¸­çš„ç»Ÿè®¡"""
        readme_path = "src/firstdata/sources/sectors/README.md"
        if not Path(readme_path).exists():
            return

        with open(readme_path, encoding="utf-8") as f:
            content = f.read()

        stats = {}

        # æå–å·²å®Œæˆæ•°é‡ï¼ˆç¬¬5è¡Œå·¦å³ï¼‰
        completed_match = re.search(r"\*\*å·²å®Œæˆ\*\*:\s*(\d+)ä¸ª", content)
        if completed_match:
            stats["completed"] = int(completed_match.group(1))

        # æå–å½“å‰å®Œæˆæ•°ï¼ˆè¿›åº¦æ¡ä¸­ï¼‰
        current_match = re.search(r"å½“å‰å®Œæˆ:\s*(\d+)\s*ä¸ª", content)
        if current_match:
            stats["current"] = int(current_match.group(1))

        self.doc_stats["sectors_readme"] = stats
        print("\n  src/firstdata/sources/sectors/README.md ç»Ÿè®¡:")
        print(f"    å·²å®Œæˆ: {stats.get('completed', 'N/A')} ä¸ª")

    def _scan_countries_readme(self):
        """æ‰«æsrc/firstdata/sources/countries/README.mdä¸­çš„ç»Ÿè®¡"""
        readme_path = "src/firstdata/sources/countries/README.md"
        if not Path(readme_path).exists():
            return

        with open(readme_path, encoding="utf-8") as f:
            content = f.read()

        stats = {}

        # æå–å½“å‰å®Œæˆæ•°ï¼ˆè¿›åº¦æ¡ä¸­ï¼‰
        current_match = re.search(r"å½“å‰å®Œæˆ:\s*(\d+)\s*ä¸ª", content)
        if current_match:
            stats["current"] = int(current_match.group(1))

        self.doc_stats["countries_readme"] = stats
        print("\n  src/firstdata/sources/countries/README.md ç»Ÿè®¡:")
        print(f"    å½“å‰å®Œæˆ: {stats.get('current', 'N/A')} ä¸ª")

    def compare(self):
        """å¯¹æ¯”å®é™…æ•°æ®æºå’Œæ–‡æ¡£"""
        print("\n" + "=" * 80)
        print("æ­¥éª¤3: å¯¹æ¯”å·®å¼‚")
        print("=" * 80)

        report = {"summary": {}, "missing_in_docs": {}, "stats_mismatch": [], "recommendations": []}

        # 1. å¯¹æ¯”å„åˆ†ç±»çš„æ•°é‡
        print("\nã€æ•°é‡å¯¹æ¯”ã€‘")
        print(f"{'åˆ†ç±»':<15} {'å®é™…':<8} {'æ–‡æ¡£':<8} {'å·®å¼‚':<8} çŠ¶æ€")
        print("-" * 50)

        for category in ["international", "china", "countries", "academic", "sectors"]:
            actual_count = self.actual_sources["by_category"].get(category, 0)
            doc_count = len(self.doc_entries[category]["found"])
            diff = actual_count - doc_count
            status = "âœ…" if diff == 0 else "âŒ"

            print(f"{category:<15} {actual_count:<8} {doc_count:<8} {diff:<8} {status}")

            report["summary"][category] = {
                "actual": actual_count,
                "in_docs": doc_count,
                "diff": diff,
            }

        # 2. æ‰¾å‡ºæ–‡æ¡£ä¸­ç¼ºå¤±çš„æ•°æ®æº
        print("\nã€ç¼ºå¤±æ¡ç›®è¯¦æƒ…ã€‘")
        for category in ["international", "china", "countries", "academic", "sectors"]:
            # ä½¿ç”¨filename_idæ¥åŒ¹é…ï¼ˆå› ä¸ºREADMEä¸­ä½¿ç”¨æ–‡ä»¶åï¼Œä¸æ˜¯JSONçš„idå­—æ®µï¼‰
            actual_ids = {s["filename_id"] for s in self.actual_sources["all"].get(category, [])}
            doc_ids = self.doc_entries[category]["found"]
            missing_ids = actual_ids - doc_ids

            if missing_ids:
                report["missing_in_docs"][category] = []
                print(f"\n{category.upper()} - ç¼ºå¤± {len(missing_ids)} ä¸ª:")

                for source in self.actual_sources["all"][category]:
                    if source["filename_id"] in missing_ids:
                        print(f"  âŒ {source['name_en']} ({source['id']})")
                        print(f"     è·¯å¾„: {source['path']}")
                        report["missing_in_docs"][category].append(source)

        # 3. å¯¹æ¯”æ ¸å¿ƒæ–‡æ¡£ä¸­çš„ç»Ÿè®¡æ•°å­—
        print("\nã€æ ¸å¿ƒæ–‡æ¡£ç»Ÿè®¡å¯¹æ¯”ã€‘")
        actual_total = self.actual_sources["total"]

        docs_with_stats = [
            ("README.mdå¾½ç« ", self.doc_stats.get("main_readme", {}).get("total_in_badge")),
            ("README.mdè¡¨æ ¼", self.doc_stats.get("main_readme", {}).get("total_in_table")),
        ]

        for doc_name, doc_total in docs_with_stats:
            if doc_total is not None:
                match = "âœ…" if doc_total == actual_total else "âŒ"
                print(f"  {doc_name:<20}: {doc_total:>3} (å®é™…: {actual_total}) {match}")

                if doc_total != actual_total:
                    report["stats_mismatch"].append(
                        {"doc": doc_name, "current": doc_total, "should_be": actual_total}
                    )

        # 4. å¯¹æ¯”åˆ†ç±»READMEä¸­çš„ç»Ÿè®¡æ•°å­—
        print("\nã€åˆ†ç±»READMEç»Ÿè®¡å¯¹æ¯”ã€‘")

        # China README
        actual_china = self.actual_sources["by_category"].get("china", 0)
        china_completed = self.doc_stats.get("china_readme", {}).get("completed")
        if china_completed is not None:
            match = "âœ…" if china_completed == actual_china else "âŒ"
            print(
                f"  src/firstdata/sources/china/README.md: {china_completed:>3} (å®é™…: {actual_china}) {match}"
            )
            if china_completed != actual_china:
                report["stats_mismatch"].append(
                    {
                        "doc": "src/firstdata/sources/china/README.md",
                        "current": china_completed,
                        "should_be": actual_china,
                    }
                )

        # Sectors README
        actual_sectors = self.actual_sources["by_category"].get("sectors", 0)
        sectors_completed = self.doc_stats.get("sectors_readme", {}).get("completed")
        if sectors_completed is not None:
            match = "âœ…" if sectors_completed == actual_sectors else "âŒ"
            print(
                f"  src/firstdata/sources/sectors/README.md: {sectors_completed:>3} (å®é™…: {actual_sectors}) {match}"
            )
            if sectors_completed != actual_sectors:
                report["stats_mismatch"].append(
                    {
                        "doc": "src/firstdata/sources/sectors/README.md",
                        "current": sectors_completed,
                        "should_be": actual_sectors,
                    }
                )

        # Countries README
        actual_countries = self.actual_sources["by_category"].get("countries", 0)
        countries_current = self.doc_stats.get("countries_readme", {}).get("current")
        if countries_current is not None:
            match = "âœ…" if countries_current == actual_countries else "âŒ"
            print(
                f"  src/firstdata/sources/countries/README.md: {countries_current:>3} (å®é™…: {actual_countries}) {match}"
            )
            if countries_current != actual_countries:
                report["stats_mismatch"].append(
                    {
                        "doc": "src/firstdata/sources/countries/README.md",
                        "current": countries_current,
                        "should_be": actual_countries,
                    }
                )

        # 5. ç”Ÿæˆæ›´æ–°å»ºè®®
        print("\n" + "=" * 80)
        print("æ­¥éª¤4: æ›´æ–°å»ºè®®")
        print("=" * 80)

        total_missing = sum(len(v) for v in report["missing_in_docs"].values())
        total_stats_issues = len(report["stats_mismatch"])

        print("\nğŸ“Š æ€»ç»“:")
        print(f"  â€¢ å®é™…æ•°æ®æºæ€»æ•°: {actual_total}")
        print(f"  â€¢ ç¼ºå¤±æ–‡æ¡£æ¡ç›®: {total_missing} ä¸ª")
        print(f"  â€¢ ç»Ÿè®¡æ•°å­—é”™è¯¯: {total_stats_issues} å¤„")

        if total_missing > 0:
            print("\nğŸ“ éœ€è¦æ›´æ–°çš„æ–‡æ¡£:")
            for category, missing in report["missing_in_docs"].items():
                if missing:
                    print(f"  â€¢ sources/{category}/README.md - æ·»åŠ  {len(missing)} ä¸ªæ¡ç›®")
                    report["recommendations"].append(
                        {
                            "action": "add_entries",
                            "file": f"sources/{category}/README.md",
                            "count": len(missing),
                            "sources": missing,
                        }
                    )

        if total_stats_issues > 0:
            print("\nğŸ”¢ éœ€è¦æ›´æ–°ç»Ÿè®¡æ•°å­—çš„æ–‡æ¡£:")
            files_to_update = {item["doc"].split("(")[0] for item in report["stats_mismatch"]}
            for file in files_to_update:
                print(f"  â€¢ {file} - æ›´æ–°æ€»æ•°ä¸º {actual_total}")
                report["recommendations"].append(
                    {"action": "update_stats", "file": file, "new_total": actual_total}
                )

        return report

    def save_report(self, report):
        """ä¿å­˜å¯¹æ¯”æŠ¥å‘Š"""
        output_file = ".claude/skills/firstdata-publisher/scripts/comparison_report.json"
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(report, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ’¾ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {output_file}")
        return output_file


def main():
    print("æ•°æ®æºæ–‡æ¡£æ£€æŸ¥å’Œå¯¹æ¯”å·¥å…·")
    print("=" * 80)

    checker = DataSourceChecker()

    # 1. æ‰«æå®é™…æ•°æ®æº
    checker.scan_actual_sources()

    # 2. æ‰«ææ–‡æ¡£
    checker.scan_docs()

    # 3. å¯¹æ¯”
    report = checker.compare()

    # 4. ä¿å­˜æŠ¥å‘Š
    checker.save_report(report)

    print("\n" + "=" * 80)
    print("âœ… æ£€æŸ¥å®Œæˆ")
    print("=" * 80)


if __name__ == "__main__":
    main()
