#!/usr/bin/env python3
"""
è‡ªåŠ¨ç»Ÿè®¡æ•°æ®æºå¹¶æ›´æ–°æ‰€æœ‰æ–‡æ¡£æ–‡ä»¶

å®Œæ•´å®ç° SKILL.md ç¬¬8æ­¥çš„æ‰€æœ‰æ–‡æ¡£æ›´æ–°ï¼š
- 8.1: ä¸€çº§ç›®å½• READMEï¼ˆæ·»åŠ æ•°æ®æºæ¡ç›®ï¼‰
- 8.2: è¿›åº¦ç»Ÿè®¡ï¼ˆ3ä¸ªæ–‡ä»¶çš„æ•°å­—åŒæ­¥ï¼‰

ä½¿ç”¨æ–¹æ³•ï¼š
    python .claude/skills/datasource-scraper/scripts/update_all_docs.py
    python .claude/skills/datasource-scraper/scripts/update_all_docs.py --dry-run
    python .claude/skills/datasource-scraper/scripts/update_all_docs.py --only-stats  # ä»…æ›´æ–°è¿›åº¦ç»Ÿè®¡
"""

import argparse
import json
import re
import sys
from datetime import datetime
from pathlib import Path


class DocumentUpdater:
    """æ–‡æ¡£æ›´æ–°å™¨ - å®Œæ•´å®ç° SKILL.md ç¬¬8æ­¥"""

    def __init__(self, base_dir: Path, dry_run: bool = False, verbose: bool = False):
        self.base_dir = base_dir
        self.sources_dir = base_dir / "src" / "firstdata" / "sources"
        self.dry_run = dry_run
        self.verbose = verbose

        # æ–‡ä»¶è·¯å¾„
        self.readme_path = base_dir / "README.md"

        # Sources ç›®å½• README
        self.sources_readme_paths = {
            "international": self.sources_dir / "international" / "README.md",
            "china": self.sources_dir / "china" / "README.md",
            "countries": self.sources_dir / "countries" / "README.md",
            "academic": self.sources_dir / "academic" / "README.md",
            "sectors": self.sources_dir / "sectors" / "README.md",
        }

        # ç»Ÿè®¡æ•°æ®
        self.stats = {
            "total": 0,
            "international": 0,
            "china": 0,
            "countries": 0,
            "academic": 0,
            "sectors": 0,
        }

        # æ•°æ®æºè¯¦ç»†åˆ—è¡¨
        self.datasources = {
            "international": [],
            "china": [],
            "countries": [],
            "academic": [],
            "sectors": [],
        }

        # è´¨é‡è¯„åˆ†
        self.quality_scores = []

        # æ›´æ–°è®¡æ•°å™¨
        self.updates = {
            "readme": False,
            "sources_readmes": set(),
        }

    def log(self, message: str, force: bool = False):
        """è¾“å‡ºæ—¥å¿—"""
        if self.verbose or force:
            print(message)

    def scan_datasources(self):
        """æ‰«ææ‰€æœ‰æ•°æ®æºæ–‡ä»¶å¹¶ç»Ÿè®¡"""
        self.log("ğŸ” æ‰«ææ•°æ®æºæ–‡ä»¶...", force=True)

        for category in ["international", "china", "countries", "academic", "sectors"]:
            category_dir = self.sources_dir / category
            if not category_dir.exists():
                continue

            json_files = list(category_dir.rglob("*.json"))
            self.stats[category] = len(json_files)

            self.log(f"  {category}: {len(json_files)} ä¸ªæ–‡ä»¶")

            # è¯»å–æ¯ä¸ªæ•°æ®æºçš„è¯¦ç»†ä¿¡æ¯
            for json_file in json_files:
                try:
                    with open(json_file, encoding="utf-8") as f:
                        data = json.load(f)

                    # æå–ä¿¡æ¯
                    ds_info = {
                        "id": data.get("id", ""),
                        "name_zh": data.get("name", {}).get("zh", ""),
                        "name_en": data.get("name", {}).get("en", ""),
                        "authority": data.get("quality", {}).get("authority_level", 0),
                        "file_path": str(json_file.relative_to(self.base_dir)),
                        "relative_path": str(json_file.relative_to(category_dir)),
                    }

                    # è®¡ç®—å¹³å‡è´¨é‡ï¼ˆåªä½¿ç”¨6ä¸ªæ ‡å‡†è¯„åˆ†å­—æ®µï¼‰
                    quality = data.get("quality", {})
                    if quality:
                        quality_fields = [
                            "authority_level",
                            "methodology_transparency",
                            "update_timeliness",
                            "data_completeness",
                            "documentation_quality",
                            "citation_count",
                        ]
                        scores = [
                            quality[field]
                            for field in quality_fields
                            if field in quality and isinstance(quality[field], (int, float))
                        ]
                        if scores:
                            avg_quality = sum(scores) / len(scores)
                            self.quality_scores.append(avg_quality)
                            ds_info["avg_quality"] = avg_quality

                    # è·å–æ•°æ®æ ¼å¼
                    formats = data.get("data_content", {}).get("formats", [])
                    if not formats and "download" in data.get("access", {}):
                        formats = data["access"]["download"].get("formats", [])
                    ds_info["formats"] = formats[:3] if formats else []

                    # è·å–è®¿é—®ç±»å‹
                    ds_info["access_level"] = data.get("access", {}).get("access_level", "unknown")

                    self.datasources[category].append(ds_info)

                except Exception as e:
                    self.log(f"  âš ï¸  è¯»å–æ–‡ä»¶å¤±è´¥: {json_file} - {e}")

        self.stats["total"] = sum(
            [self.stats[k] for k in ["international", "china", "countries", "academic", "sectors"]]
        )

        self.log(f"\nâœ… æ‰«æå®Œæˆï¼Œå…±æ‰¾åˆ° {self.stats['total']} ä¸ªæ•°æ®æº", force=True)
        return self.stats

    def calculate_progress(self) -> dict[str, int]:
        """è®¡ç®—è¿›åº¦ç™¾åˆ†æ¯”"""
        targets = {
            "total": 950,
            "international": 100,
            "china": 488,
            "countries": 200,
            "academic": 50,
            "sectors": 150,
        }

        progress = {}
        for key, current in self.stats.items():
            target = targets[key]
            progress[key] = round((current / target) * 100) if target > 0 else 0

        return progress

    def calculate_avg_quality(self) -> float:
        """è®¡ç®—å¹³å‡è´¨é‡è¯„åˆ†"""
        if not self.quality_scores:
            return 5.0
        return round(sum(self.quality_scores) / len(self.quality_scores), 1)

    def generate_report(self) -> str:
        """ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š"""
        progress = self.calculate_progress()
        avg_quality = self.calculate_avg_quality()

        report = []
        report.append("=" * 60)
        report.append("ğŸ“Š æ•°æ®æºç»Ÿè®¡æŠ¥å‘Š")
        report.append("=" * 60)
        report.append("")
        report.append(f"æ€»æ•°æ®æº: {self.stats['total']} / 950+ ({progress['total']}%)")
        report.append(
            f"å›½é™…ç»„ç»‡: {self.stats['international']} / 100+ ({progress['international']}%)"
        )
        report.append(f"ä¸­å›½æ•°æ®æº: {self.stats['china']} / 488 ({progress['china']}%)")
        report.append(f"å„å›½å®˜æ–¹: {self.stats['countries']} / 200+ ({progress['countries']}%)")
        report.append(f"å­¦æœ¯ç ”ç©¶: {self.stats['academic']} / 50+ ({progress['academic']}%)")
        report.append(f"è¡Œä¸šé¢†åŸŸ: {self.stats['sectors']} / 150+ ({progress['sectors']}%)")
        report.append("")
        report.append(f"å¹³å‡è´¨é‡è¯„åˆ†: {avg_quality}/5.0")
        report.append("")
        report.append("=" * 60)

        return "\n".join(report)

    # ========== 8.3.1: æ›´æ–°æ ¹ç›®å½• README.md ==========

    def update_readme(self) -> bool:
        """æ›´æ–° README.md"""
        self.log("ğŸ“ æ›´æ–° README.md...", force=True)

        if not self.readme_path.exists():
            self.log("âŒ README.md ä¸å­˜åœ¨", force=True)
            return False

        with open(self.readme_path, encoding="utf-8") as f:
            original_content = f.read()

        content = original_content
        content = self._update_readme_badges(content)
        content = self._update_readme_stats_table(content)
        content = self._update_readme_datasource_lists(content)
        content = self._update_readme_project_status(content)

        if content == original_content:
            self.log("  â„¹ï¸  æ²¡æœ‰éœ€è¦æ›´æ–°çš„å†…å®¹", force=True)
            return False

        if not self.dry_run:
            with open(self.readme_path, "w", encoding="utf-8") as f:
                f.write(content)
            self.log("  âœ… README.md å·²æ›´æ–°", force=True)
        else:
            self.log("  ğŸ” [DRY RUN] æ£€æµ‹åˆ°å˜æ›´", force=True)

        self.updates["readme"] = True
        return True

    def _update_readme_badges(self, content: str) -> str:
        """æ›´æ–°READMEé¡¶éƒ¨å¾½ç« """
        progress = self.calculate_progress()
        avg_quality = self.calculate_avg_quality()

        # æ›´æ–°æ•°æ®æºæ•°é‡
        content = re.sub(
            r"\[\!\[Data Sources\]\(https://img\.shields\.io/badge/Data%20Sources-\d+%2F950\+-blue\.svg\)\]",
            f"[![Data Sources](https://img.shields.io/badge/Data%20Sources-{self.stats['total']}%2F950+-blue.svg)]",
            content,
        )

        # æ›´æ–°è¿›åº¦
        content = re.sub(
            r"\[\!\[Progress\]\(https://img\.shields\.io/badge/Progress-\d+%25-yellow\.svg\)\]",
            f"[![Progress](https://img.shields.io/badge/Progress-{progress['total']}%25-yellow.svg)]",
            content,
        )

        # æ›´æ–°è´¨é‡è¯„åˆ†
        content = re.sub(
            r"\[\!\[Quality Rating\]\(https://img\.shields\.io/badge/Avg%20Quality-[\d.]+%2F5\.0-brightgreen\.svg\)\]",
            f"[![Quality Rating](https://img.shields.io/badge/Avg%20Quality-{avg_quality}%2F5.0-brightgreen.svg)]",
            content,
        )

        return content

    def _update_readme_stats_table(self, content: str) -> str:
        """æ›´æ–°æ€»ä½“ç»Ÿè®¡è¡¨æ ¼"""
        progress = self.calculate_progress()

        table_lines = [
            "| æŒ‡æ ‡ | å½“å‰/ç›®æ ‡ | è¿›åº¦ |",
            "|------|-----------|------|",
            f"| **æ€»æ•°æ®æº** | {self.stats['total']} / 950+ | {progress['total']}% |",
            f"| **å›½é™…ç»„ç»‡** | {self.stats['international']} / 100+ | {progress['international']}% |",
            f"| **å„å›½å®˜æ–¹** | {self.stats['countries']} / 200+ | {progress['countries']}% |",
            f"| **ä¸­å›½æ•°æ®æº** | {self.stats['china']} / 488 | {progress['china']}% |",
            f"| **å­¦æœ¯ç ”ç©¶** | {self.stats['academic']} / 50+ | {progress['academic']}% |",
            f"| **è¡Œä¸šé¢†åŸŸ** | {self.stats['sectors']} / 150+ | {progress['sectors']}% |",
        ]

        new_table = "\n".join(table_lines)
        pattern = r"\| æŒ‡æ ‡ \| å½“å‰/ç›®æ ‡ \| è¿›åº¦ \|.*?\| \*\*è¡Œä¸šé¢†åŸŸ\*\* \|[^\n]*"
        content = re.sub(pattern, new_table, content, flags=re.DOTALL)

        return content

    def _update_readme_datasource_lists(self, content: str) -> str:
        """æ›´æ–°å·²å®Œæˆæ•°æ®æºåˆ—è¡¨æ ‡é¢˜ä¸­çš„æ•°é‡"""
        for category, count in [
            ("international", self.stats["international"]),
            ("china", self.stats["china"]),
            ("countries", self.stats["countries"]),
            ("academic", self.stats["academic"]),
            ("sectors", self.stats["sectors"]),
        ]:
            patterns = {
                "international": r"#### ğŸŒ å›½é™…ç»„ç»‡ \(\d+ä¸ª\)",
                "china": r"#### ğŸ‡¨ğŸ‡³ ä¸­å›½æ•°æ®æº \(\d+ä¸ª\)",
                "countries": r"#### ğŸŒ å„å›½å®˜æ–¹ \(\d+ä¸ª\)",
                "academic": r"#### ğŸ“ å­¦æœ¯ç ”ç©¶ \(\d+ä¸ª\)",
                "sectors": r"#### ğŸ­ è¡Œä¸šé¢†åŸŸ \(\d+ä¸ª\)",
            }
            replacements = {
                "international": f"#### ğŸŒ å›½é™…ç»„ç»‡ ({count}ä¸ª)",
                "china": f"#### ğŸ‡¨ğŸ‡³ ä¸­å›½æ•°æ®æº ({count}ä¸ª)",
                "countries": f"#### ğŸŒ å„å›½å®˜æ–¹ ({count}ä¸ª)",
                "academic": f"#### ğŸ“ å­¦æœ¯ç ”ç©¶ ({count}ä¸ª)",
                "sectors": f"#### ğŸ­ è¡Œä¸šé¢†åŸŸ ({count}ä¸ª)",
            }

            if category in patterns:
                content = re.sub(patterns[category], replacements[category], content)

        return content

    def _update_readme_project_status(self, content: str) -> str:
        """æ›´æ–°é¡¹ç›®çŠ¶æ€è¡¨æ ¼"""
        progress = self.calculate_progress()
        avg_quality = self.calculate_avg_quality()
        today = datetime.now().strftime("%Y-%m-%d")

        status_lines = [
            "| æŒ‡æ ‡ | çŠ¶æ€ |",
            "|------|------|",
            "| **å½“å‰é‡Œç¨‹ç¢‘** | M0 å®Œæˆ âœ… / M1 è¿›è¡Œä¸­ ğŸš§ |",
            f"| **æ€»ä½“è¿›åº¦** | {self.stats['total']} / 950+ ({progress['total']}%) |",
            f"| **å®Œæˆåº¦** | å›½é™…ç»„ç»‡ {progress['international']}%ã€ä¸­å›½ {progress['china']}%ã€å­¦æœ¯ {progress['academic']}% |",
            f"| **æœ€è¿‘æ›´æ–°** | {today} |",
            f"| **è´¨é‡è¯„åˆ†** | â­â­â­â­â­ ({avg_quality}/5.0) |",
        ]

        new_status = "\n".join(status_lines)
        pattern = r"## ğŸ“Š é¡¹ç›®çŠ¶æ€ \| Project Status\s*\n\s*\| æŒ‡æ ‡ \| çŠ¶æ€ \|.*?\| \*\*è´¨é‡è¯„åˆ†\*\* \|[^\n]*"
        replacement = f"## ğŸ“Š é¡¹ç›®çŠ¶æ€ | Project Status\n\n{new_status}"
        content = re.sub(pattern, replacement, content, flags=re.DOTALL)

        return content

    # ========== ä¸»æµç¨‹ ==========

    def run(self, only_stats: bool = False) -> int:
        """æ‰§è¡Œå®Œæ•´çš„æ›´æ–°æµç¨‹"""
        try:
            # 1. æ‰«ææ•°æ®æº
            self.scan_datasources()

            # 2. ç”ŸæˆæŠ¥å‘Š
            report = self.generate_report()
            print("\n" + report)

            # 3. æ›´æ–°æ‰€æœ‰æ–‡ä»¶
            print("\n" + "=" * 60)
            print("ğŸ“ å¼€å§‹æ›´æ–°æ–‡æ¡£...")
            print("=" * 60 + "\n")

            # 8.2.1: æ›´æ–°æ ¹ç›®å½• README
            self.update_readme()

            # TODO: 8.2.2: æ›´æ–° src/firstdata/sources/*/README.mdï¼ˆæ•°æ®æºåˆ—è¡¨ï¼‰

            # 4. æ€»ç»“
            print("\n" + "=" * 60)
            if self.dry_run:
                print("ğŸ” DRY RUN æ¨¡å¼ - æœªè¿›è¡Œå®é™…ä¿®æ”¹")
            else:
                print("âœ… æ›´æ–°å®Œæˆ")

            updated_files = []
            if self.updates["readme"]:
                updated_files.append("README.md")

            if updated_files:
                status = "æ£€æµ‹åˆ°å˜æ›´" if self.dry_run else "å·²æ›´æ–°"
                print(f"\nğŸ“ {status}çš„æ–‡ä»¶:")
                for f in updated_files:
                    print(f"  - {f}")
            else:
                print("\nâ„¹ï¸  æ‰€æœ‰æ–‡ä»¶å·²æ˜¯æœ€æ–°çŠ¶æ€")

            print("=" * 60)

            return 0

        except Exception as e:
            print(f"\nâŒ é”™è¯¯: {e}", file=sys.stderr)
            if self.verbose:
                import traceback

                traceback.print_exc()
            return 1


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="è‡ªåŠ¨ç»Ÿè®¡æ•°æ®æºå¹¶æ›´æ–°æ‰€æœ‰æ–‡æ¡£æ–‡ä»¶",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
å®Œæ•´å®ç° SKILL.md ç¬¬8æ­¥çš„æ–‡æ¡£æ›´æ–°ï¼š
  8.1: ä¸€çº§ç›®å½• READMEï¼ˆæ·»åŠ æ•°æ®æºæ¡ç›®ï¼‰- TODO
  8.2: è¿›åº¦ç»Ÿè®¡ï¼ˆ2ä¸ªæ–‡ä»¶çš„æ•°å­—åŒæ­¥ï¼‰- âœ… å·²å®ç°1ä¸ª

ç¤ºä¾‹:
  %(prog)s                    # ç»Ÿè®¡å¹¶æ›´æ–°æ‰€æœ‰æ–‡ä»¶
  %(prog)s --dry-run          # ä»…æ˜¾ç¤ºå˜æ›´ï¼Œä¸å®é™…ä¿®æ”¹
  %(prog)s --verbose          # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
  %(prog)s --only-stats       # ä»…æ›´æ–°è¿›åº¦ç»Ÿè®¡æ–‡ä»¶
        """,
    )

    parser.add_argument(
        "--dry-run", action="store_true", help="ä»…æ˜¾ç¤ºå°†è¦è¿›è¡Œçš„å˜æ›´ï¼Œä¸å®é™…ä¿®æ”¹æ–‡ä»¶"
    )

    parser.add_argument("--verbose", "-v", action="store_true", help="æ˜¾ç¤ºè¯¦ç»†çš„æ‰§è¡Œä¿¡æ¯")

    parser.add_argument("--only-stats", action="store_true", help="ä»…æ›´æ–°è¿›åº¦ç»Ÿè®¡æ–‡ä»¶ï¼ˆREADMEï¼‰")

    parser.add_argument(
        "--base-dir", type=Path, default=Path.cwd(), help="é¡¹ç›®æ ¹ç›®å½•è·¯å¾„ï¼ˆé»˜è®¤ï¼šå½“å‰ç›®å½•ï¼‰"
    )

    args = parser.parse_args()

    # åˆ›å»ºæ›´æ–°å™¨å¹¶è¿è¡Œ
    updater = DocumentUpdater(base_dir=args.base_dir, dry_run=args.dry_run, verbose=args.verbose)

    return updater.run(only_stats=args.only_stats)


if __name__ == "__main__":
    sys.exit(main())
